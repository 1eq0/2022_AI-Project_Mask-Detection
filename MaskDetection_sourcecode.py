# -*- coding: utf-8 -*-
"""2022-1_AI_FinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xVp0Cha3gttuQS97q4FObUxK1uKE-BYw
"""

# 2022-1 인공지능 Team Project - final code
###### Mask Detection ######
# B811149 이채정, B911017 김다인, B811206 한은영, B889041 신혜민

# 구글 드라이브 연결
from google.colab import drive
drive.mount('/content/drive')

# kaggle.json 파일 업로드
from google.colab import files 
files.upload()

# Kaggle에서 데이터를 불러옴
!pip install kaggle --upgrade

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d ashishjangra27/face-mask-12k-images-dataset

!unzip face-mask-12k-images-dataset.zip

# 런타임 유형: GPU
# regularization:Dropout / optimizer='Nadam' 이외엔 주석으로 처리

import tensorflow as tf
import numpy as np

from keras.applications.vgg16 import VGG16
from keras import models,Input,Sequential
from tensorflow.keras import optimizers
from keras.layers import Flatten, Dense, Dropout
from keras.callbacks import EarlyStopping

from keras.preprocessing.image import load_img, img_to_array, image_dataset_from_directory, ImageDataGenerator
from IPython.display import display
import matplotlib.pyplot as plt
from tensorflow.keras.utils import plot_model

# 데이터가 저장된 directory를 변수로 저장
train_dir = '/content/Face Mask Dataset/Train'
test_dir = '/content/Face Mask Dataset/Test'
val_dir = '/content/Face Mask Dataset/Validation'

BATCH_SIZE = 32
IMG_SIZE = 64
DROP_RATE = 0.3  # 0.3, 0.5 두 가지를 바꿔보며 실험

# normalization
def process(image,label):
    image = tf.cast(image/255. ,tf.float32)  # RGB feature normalization
    return image,label


###### 데이터 증강 전 ######
# train_data = image_dataset_from_directory(train_dir,labels='inferred', image_size=(IMG_SIZE,IMG_SIZE),shuffle=True, label_mode='binary').map(process)
# test_data = image_dataset_from_directory(test_dir,labels='inferred', image_size=(IMG_SIZE,IMG_SIZE),shuffle=True, label_mode='binary').map(process)
# val_data = image_dataset_from_directory(val_dir,labels='inferred', image_size=(IMG_SIZE,IMG_SIZE),shuffle=True, label_mode='binary').map(process)   

###### 데이터 증강 적용 ######
train_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(IMG_SIZE, IMG_SIZE),
        batch_size=BATCH_SIZE,
        class_mode='binary')

test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(IMG_SIZE, IMG_SIZE),
        batch_size=BATCH_SIZE,
        class_mode='binary')

val_datagen = ImageDataGenerator(rescale=1./255)
val_generator = val_datagen.flow_from_directory(
        val_dir,
        target_size=(IMG_SIZE, IMG_SIZE),
        batch_size=BATCH_SIZE,
        class_mode='binary')


# imagenet으로 pre-trained된 네트워크를 사용 - 전이학습 
pre_trained_model = VGG16(  # 기본 모델 VGG16
    weights='imagenet',     # imagenet 사용
    include_top=False,
    input_tensor=Input(shape=(IMG_SIZE,IMG_SIZE,3))
)

# 특징 추출 - 레이어의 가중치가 훈련 중에 업데이트 되는 것을 방지
pre_trained_model.trainable = False

#pre-trained model의 architecture 살펴보기
#pre_trained_model.summary()
plot_model(pre_trained_model,to_file='pre_trained_model.png',show_shapes=True)

# 선택한 regularization 방식 적용하기 전에는 early stop만 사용
# early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)


###### classifier 연결 ######
# regularization 기법 변경해가며(dropout, L2) 실험

# Regularization : Dropout
model = Sequential([  # Overfitting 방지를 위해 데이터 processing 적용
  tf.keras.layers.experimental.preprocessing.RandomFlip("horizontal_and_vertical"),   # 데이터 RandomFlip
  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2), # 데이터 RandomRotation
])
model.add(pre_trained_model)
model.add(Flatten())
model.add(Dropout(DROP_RATE)) 
model.add(Dense(1024,activation='relu'))
model.add(Dropout(DROP_RATE))
model.add(Dense(1,activation='sigmoid'))
#model.summary()
#plot_model(model,to_file='model.png',show_shapes=True)

'''
# Regularization : L2
model = Sequential([
  tf.keras.layers.experimental.preprocessing.RandomFlip("horizontal_and_vertical"),
  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),
])
model.add(pre_trained_model)
model.add(Flatten())
model.add(Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001)))  # regularization parameter: 0.001
model.add(Dense(1, activation='sigmoid'))
'''


# model training - fit_generator
# optimizer 바꿔가며 실험 & 'adam', 'Nadam'으로 결과 도출
model.compile(optimizer='Nadam',loss='binary_crossentropy',metrics='accuracy')  # optimizer='adam'
history=model.fit_generator(train_generator, # 증강된 데이터 사용
                  validation_data = val_generator,
                  epochs=30)  # epoch 값 바꿔가며 실험
                  #callbacks = [early_stopping])

#결과 plotting
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1,len(acc)+1) # epoch 진행 상황 plotting

# graph plotting
# accuracy plotting
plt.plot(epochs, acc, 'bo', label = 'Training acc')
plt.plot(epochs, val_acc, 'b', label = 'Validation acc')
plt.title('Accuracy')
plt.legend()
plt.figure()

# loss plotting
plt.plot(epochs, loss, 'ro', label = 'Training loss')
plt.plot(epochs, val_loss, 'r', label = 'Validation loss')
plt.title('Loss')
plt.legend()

plt.show()

# test data로 모델 성능 평가 - evaluate
test_loss, test_acc = model.evaluate_generator(test_generator)
print(f"test_loss = {test_loss} \ntest_acc = {test_acc}")  # loss, accuracy 출력

# 새로운 데이터 넣어서 클래스 예측 결과 확인하기: 팀원 사진 & 일러스트

from tensorflow.keras.utils import load_img
import os
import random

new_dir = '/content/Face Mask Dataset/NewTest'

# New Test image load & predict
def sample_test(directory):
    print("-"*100)
    new_img = load_img(directory)
    plt.imshow(new_img)
    new_img = load_img(directory,target_size=(IMG_SIZE,IMG_SIZE))
    new_img = np.array(new_img).astype('float32')/255  # RGB feature normalization
    new_img = np.expand_dims(new_img,axis=0)

    # predict: NoMask 0 <--------> 1 Mask
    if model.predict(new_img)[0][0]>0.5:  # Mask off일 확률이므로, 1-(model.predict)하여 NoMask라면 0에 가까워지도록 설정
        print(f"Predicted: No Mask\nProbaility score ", np.round(1-model.predict(new_img)[0][0],2)) # No Mask
    else:
        print(f"Predicted: Mask\nProbaility score ", np.round(1-model.predict(new_img)[0][0],2)) # Mask
    plt.show()


# predict 결과 확인
listOfFiles = list()
for (dirpath, dirnames, filenames) in os.walk(new_dir):
    listOfFiles += [os.path.join(dirpath, file) for file in filenames]

for sample in listOfFiles:
    sample_test(sample)